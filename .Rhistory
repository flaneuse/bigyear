source('~/GitHub/Rplots/themes_ldh.r')
# Read in data ------------------------------------------------------------
url = 'https://docs.google.com/spreadsheets/d/1RWZuaNEqARhlfzXK-ZvKhm3RwNSFpirFXfSRnuFB25o/pub?output=csv'
# Note: sheet must be published to the web for connection to work.
gap = url %>% gs_url(visibility = 'private')
mj = gap %>% gs_read(ws = 1)
nr = gap %>% gs_read(ws = 2)
l = gap %>% gs_read(ws = 3)
mj = bigyearWS %>%
gs_read(ws = 1) %>%
mutate(team = `Michael and Jing`)
bigyearWS = url %>% gs_url(visibility = 'private')
mj = bigyearWS %>%
gs_read(ws = 1) %>%
mutate(team = `Michael and Jing`)
mj = bigyearWS %>%
gs_read(ws = 1) %>%
mutate(team = 'Michael and Jing')
View(mj)
nr = bigyearWS %>%
gs_read(ws = 2) %>%
mutate(team = 'Nancy and Rich')
l = bigyearWS %>%
gs_read(ws = 3) %>%
mutate(team = 'Laura')
by = bind_rows(mj, nr, l)
View(by)
# Clean up the data -------------------------------------------------------
# Merge datasets together
by = bind_rows(mj, nr, l) %>%
mutate(Species = str_to_lower(Species), # Strip out upper case chars
Location = str_to_lower(Location),
State = str_to_upper(State))
install.packages('llama')
remove.packages("llama")
# Import bird species of North America list -------------------------------
# Source: Cornerll's Bird's of North America Online
# http://bna.birds.cornell.edu/bna/species
library(rvest)
library(dplyr)
library(data.table)
# Load in the data --------------------------------------------------------
# As of 28 December 2015, should have 748 birds in N. Amer.
bna = read_html('http://bna.birds.cornell.edu/bna/species')
sciNames = bna %>%
html_nodes(".sci-name") %>%
html_text()
sciNames = data.frame(sciName = sciNames)
commonNames = bna %>%
html_nodes("#region-content a span") %>%
html_text()
commonNames = data.frame(commonName = commonNames)
links = bna %>%
html_nodes("#region-content .float-left a") %>%
html_attr("href")
# Filter the links to the alpha bar.
# Not the classiest, and may lead to mismatching of birds to links.
links = data.frame(link = links) %>%
filter(link %like% "/bna/species")
# Merge together full bird dataset ----------------------------------------
birdDB = bind_cols(commonNames, sciNames, links) %>%
rowwise() %>%
mutate(id = as.numeric(paste0(str_extract_all(link, '[0-9]', simplify = TRUE), collapse = "")),
link = paste0('http://bna.birds.cornell.edu', link)) # Add in unique ID, drawn from the BNA IDs
library(stringr)
sciNames = bna %>%
html_nodes(".sci-name") %>%
html_text()
sciNames = data.frame(sciName = sciNames)
commonNames = bna %>%
html_nodes("#region-content a span") %>%
html_text()
commonNames = data.frame(commonName = commonNames)
links = bna %>%
html_nodes("#region-content .float-left a") %>%
html_attr("href")
# Filter the links to the alpha bar.
# Not the classiest, and may lead to mismatching of birds to links.
links = data.frame(link = links) %>%
filter(link %like% "/bna/species")
# Merge together full bird dataset ----------------------------------------
birdDB = bind_cols(commonNames, sciNames, links) %>%
rowwise() %>%
mutate(id = as.numeric(paste0(str_extract_all(link, '[0-9]', simplify = TRUE), collapse = "")),
link = paste0('http://bna.birds.cornell.edu', link)) # Add in unique ID, drawn from the BNA IDs
n_distinct(birdDB$id)
source('~/GitHub/llamar/themes_ldh.r')
# Read in data ------------------------------------------------------------
url = 'https://docs.google.com/spreadsheets/d/1RWZuaNEqARhlfzXK-ZvKhm3RwNSFpirFXfSRnuFB25o/pub?output=csv'
# Note: sheet must be published to the web for connection to work.
bigyearWS = url %>% gs_url(visibility = 'private')
mj = bigyearWS %>%
gs_read(ws = 1) %>%
mutate(team = 'Michael and Jing')
nr = bigyearWS %>%
gs_read(ws = 2) %>%
mutate(team = 'Nancy and Rich')
l = bigyearWS %>%
gs_read(ws = 3) %>%
mutate(team = 'Laura')
# Clean up the data -------------------------------------------------------
# Merge datasets together
by = bind_rows(mj, nr, l) %>%
transmute(team = team,
species = str_to_title(Species), # Strip out upper case chars
sex = `Sex..if.known.`,
location = str_to_lower(Location),
state = str_to_upper(State),
loc = paste(location, state),
date = Date)
# Convert places to GPS coords.
gps = geocode(by$loc, output = 'latlona')
# Displace data from houses.
# Fix weird geocoords & merge into
# Check states are states.
# Check birds are unique
# Count unique species ----------------------------------------------------
cumBirds = by %>%
count(team, date) %>%
mutate(numBirds = cumsum(n))
ggplot(cumBirds, aes(x = date, y = numBirds,
group = team, colour = team)) +
geom_point()
x = left_join(by, birdDB, by = c("species" = "commonName"))
View(x)
by = bind_rows(mj, nr, l) %>%
transmute(team = team,
species = str_to_title(Species), # Strip out upper case chars
species = str_trim(species), # Trim extra spaces, if they exist
sex = `Sex..if.known.`,
location = str_to_lower(Location),
state = str_to_upper(State),
loc = paste(location, state),
date = Date)
by = left_join(by, birdDB, by = c("species" = "commonName"))
# Convert places to GPS coords.
gps = geocode(by$loc, output = 'latlona')
# Displace data from houses.
# Fix weird geocoords & merge into
# Check states are states.
# Check birds are unique
# Count unique species ----------------------------------------------------
cumBirds = by %>%
count(team, date) %>%
mutate(numBirds = cumsum(n))
ggplot(cumBirds, aes(x = date, y = numBirds,
group = team, colour = team)) +
geom_point()
View(by)
duplicated(birdDB$id)
View(birdDB[duplicated(birdDB$id)])
View(birdDB[duplicated(birdDB$id),])
str_extract('a500s', '\\d\\d\\d')
str_extract('a500s', '\\d\\d\\d[a-z]')
str_extract('a5', '\\d\\d\\d[a-z]')
birdDB = bind_cols(commonNames, sciNames, links) %>%
rowwise() %>%
mutate(bnaID = as.numeric(paste0(str_extract_all(link, '[0-9]', simplify = TRUE), collapse = "")),
id = 1:length(links),
link = paste0('http://bna.birds.cornell.edu', link)) # Add in unique ID, drawn from the BNA IDs
length(linkss)
length(links)
birdDB = bind_cols(commonNames, sciNames, links) %>%
rowwise() %>%
mutate(bnaID = as.numeric(paste0(str_extract_all(link, '[0-9]', simplify = TRUE), collapse = "")),
id = 1:nrow(links),
link = paste0('http://bna.birds.cornell.edu', link)) # Add in unique ID, drawn from the BNA IDs
ids = data.frame(id = 1:nrow(links))
# Merge together full bird dataset ----------------------------------------
birdDB = bind_cols(commonNames, sciNames, links, ids) %>%
rowwise() %>%
mutate(bnaID = as.numeric(paste0(str_extract_all(link, '[0-9]', simplify = TRUE), collapse = "")),
link = paste0('http://bna.birds.cornell.edu', link)) # Add in unique ID, drawn from the BNA IDs
colnames(mtcars)
source('~/GitHub/llamar/themes_ldh.r')
# Read in data ------------------------------------------------------------
url = 'https://docs.google.com/spreadsheets/d/1RWZuaNEqARhlfzXK-ZvKhm3RwNSFpirFXfSRnuFB25o/pub?output=csv'
# Note: sheet must be published to the web for connection to work.
bigyearWS = url %>% gs_url(visibility = 'private')
mj = bigyearWS %>%
gs_read(ws = 1) %>%
mutate(team = 'Michael and Jing')
nr = bigyearWS %>%
gs_read(ws = 2) %>%
mutate(team = 'Nancy and Rich')
l = bigyearWS %>%
gs_read(ws = 3) %>%
mutate(team = 'Laura')
# Clean up the data -------------------------------------------------------
# Merge datasets together
by = bind_rows(mj, nr, l) %>%
transmute(team = team,
species = str_to_title(Species), # Strip out upper case chars
species = str_trim(species), # Trim extra spaces, if they exist
sex = `Sex..if.known.`,
location = str_to_lower(Location),
state = str_to_upper(State),
loc = paste(location, state),
date = Date)
by = left_join(by, birdDB, by = c("species" = "commonName"))
# Convert places to GPS coords.
gps = geocode(by$loc, output = 'latlona')
# Displace data from houses.
# Fix weird geocoords & merge into
# Check states are states.
# Check birds are unique
# Count unique species ----------------------------------------------------
cumBirds = by %>%
count(team, date) %>%
mutate(numBirds = cumsum(n))
ggplot(cumBirds, aes(x = date, y = numBirds,
group = team, colour = team)) +
geom_point()
